{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCkGP0obsqInTjdGqvhKpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhbishtabhishek/ResNet-Implementation-/blob/main/ResNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "quq4sjg25PeL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, identity_downsamples=None, stride=1):\n",
        "    super(block, self).__init__()\n",
        "    self.expansion=4\n",
        "    self.conv1=nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1=nn.BatchNorm2d(out_channels)\n",
        "    self.conv2=nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2=nn.BatchNorm2d(out_channels)\n",
        "    self.conv3=nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3=nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.identity_downsamples=identity_downsamples\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity=x\n",
        "\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.bn2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv3(x)\n",
        "    x=self.bn3(x)\n",
        "\n",
        "    if self.identity_downsamples is not None:\n",
        "      identity=self.identity_downsamples(identity)\n",
        "\n",
        "    x+=identity\n",
        "    x=self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "nuB-dWrp5YN2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, image_channels, num_classes):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels=64\n",
        "    self.conv1=nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "    self.bn1=nn.BatchNorm2d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    #ResNet layers starting from here\n",
        "    self.layer1=self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "    self.layer2=self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "    self.layer3=self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "    self.layer4=self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc=nn.Linear(512*4, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.maxpool(x)\n",
        "\n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        "\n",
        "    x=self.avgpool(x)\n",
        "    x=x.reshape(x.shape[0], -1)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
        "    identity_downsample=None\n",
        "    layers=[]\n",
        "\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\n",
        "      identity_downsample=nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride), nn.BatchNorm2d(out_channels*4))\n",
        "\n",
        "      layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
        "      self.in_channels=out_channels*4\n",
        "\n",
        "      for i in range(num_residual_blocks-1):\n",
        "        layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jo_0kJP3895b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,6,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet101(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,8,36,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet152(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,23,3], img_channels, num_classes)\n"
      ],
      "metadata": {
        "id": "vvjPZ06sEB6J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet50()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auTkGaFtElpV",
        "outputId": "23c1c3c9-1e60-469b-e4ff-dbd508a450f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet101()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGvgzSTtImBb",
        "outputId": "d29fb999-adc1-4379-8fdd-20c033e60598"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet152()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm43AXHzImGC",
        "outputId": "e1c6c9ee-27a1-456f-9993-1790ea795fb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet50()\n",
        "print(\"ResNet-50 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet101()\n",
        "print(\"ResNet-101 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet152()\n",
        "print(\"ResNet-152 params:\", sum(p.numel() for p in net.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMhou0zkCNxj",
        "outputId": "0127fced-5c3b-41d8-c615-481f3dd14897"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 params: 25583592\n",
            "ResNet-101 params: 60268520\n",
            "ResNet-152 params: 44601832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "5N3asFvrC-FT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkjo1aDZC5w6",
        "outputId": "daa19c7f-94bb-4c19-fa6a-9bd4966659a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:21<00:00, 7.92MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ResNet50(img_channels=3, num_classes=10).to(device)\n"
      ],
      "metadata": {
        "id": "9XgNhw8fC_dW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "_pESAf7BDBtU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(net, trainloader, optimizer, criterion, device, epoch):\n",
        "    net.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(trainloader, leave=True)\n",
        "    for inputs, targets in loop:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        loop.set_description(f\"Epoch [{epoch}]\")\n",
        "        loop.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n",
        "\n",
        "    return running_loss/len(trainloader), 100.*correct/total\n",
        "\n"
      ],
      "metadata": {
        "id": "-wQI-QCyDDaC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, testloader, criterion, device):\n",
        "    net.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(testloader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "KhQTSWGA5fM8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZnEV7WR1dR5",
        "outputId": "1adff004-8cac-4512-a3bc-508e56e99eaf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/checkpoints/resnet_checkpoint.pth\"\n",
        "\n",
        "start_epoch = 0\n",
        "if os.path.isfile(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    net.load_state_dict(checkpoint['model_state'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(start_epoch + 1, num_epochs + 1):\n",
        "    train_loss, train_acc = train(net, trainloader, optimizer, criterion, device, epoch)\n",
        "    test_loss, test_acc = test(net, testloader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs} \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state': net.state_dict(),\n",
        "        'optimizer_state': optimizer.state_dict(),\n",
        "        'scheduler_state': scheduler.state_dict()\n",
        "    }\n",
        "    torch.save(state, checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQy8olURDFP-",
        "outputId": "f2d6a19b-7a83-47f4-e3bd-73ec9ea150ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17]: 100%|██████████| 391/391 [10:26<00:00,  1.60s/it, acc=87.2, loss=0.00285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 Train Loss: 0.3645 | Train Acc: 87.20% Test Loss: 0.5005 | Test Acc: 83.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [18]: 100%|██████████| 391/391 [10:27<00:00,  1.60s/it, acc=88.1, loss=0.00267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 Train Loss: 0.3408 | Train Acc: 88.12% Test Loss: 0.5348 | Test Acc: 82.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [19]: 100%|██████████| 391/391 [10:26<00:00,  1.60s/it, acc=88.5, loss=0.00256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100 Train Loss: 0.3271 | Train Acc: 88.51% Test Loss: 0.5375 | Test Acc: 82.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [20]: 100%|██████████| 391/391 [10:24<00:00,  1.60s/it, acc=89.2, loss=0.00239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100 Train Loss: 0.3051 | Train Acc: 89.22% Test Loss: 0.5545 | Test Acc: 81.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [21]: 100%|██████████| 391/391 [10:23<00:00,  1.59s/it, acc=90, loss=0.00227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100 Train Loss: 0.2907 | Train Acc: 89.97% Test Loss: 0.5363 | Test Acc: 82.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [22]: 100%|██████████| 391/391 [10:24<00:00,  1.60s/it, acc=90.4, loss=0.00215]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100 Train Loss: 0.2748 | Train Acc: 90.43% Test Loss: 0.5107 | Test Acc: 83.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [23]: 100%|██████████| 391/391 [10:24<00:00,  1.60s/it, acc=90.7, loss=0.00208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100 Train Loss: 0.2664 | Train Acc: 90.67% Test Loss: 0.4438 | Test Acc: 85.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [24]: 100%|██████████| 391/391 [10:23<00:00,  1.60s/it, acc=91.3, loss=0.00195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100 Train Loss: 0.2499 | Train Acc: 91.27% Test Loss: 0.4918 | Test Acc: 84.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [25]: 100%|██████████| 391/391 [10:24<00:00,  1.60s/it, acc=91.6, loss=0.00186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100 Train Loss: 0.2381 | Train Acc: 91.63% Test Loss: 0.4909 | Test Acc: 84.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [26]: 100%|██████████| 391/391 [10:24<00:00,  1.60s/it, acc=91.6, loss=0.00182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100 Train Loss: 0.2321 | Train Acc: 91.64% Test Loss: 0.5462 | Test Acc: 82.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [27]:  11%|█         | 43/391 [01:09<09:19,  1.61s/it, acc=93.8, loss=0.00142]"
          ]
        }
      ]
    }
  ]
}