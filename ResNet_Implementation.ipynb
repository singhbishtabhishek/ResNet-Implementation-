{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyNdZmCPfTdtXaUVgQUp2RTD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "quq4sjg25PeL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, identity_downsamples=None, stride=1):\n",
        "    super(block, self).__init__()\n",
        "    self.expansion=4\n",
        "    self.conv1=nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1=nn.BatchNorm2d(out_channels)\n",
        "    self.conv2=nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2=nn.BatchNorm2d(out_channels)\n",
        "    self.conv3=nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3=nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.identity_downsamples=identity_downsamples\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity=x\n",
        "\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.bn2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv3(x)\n",
        "    x=self.bn3(x)\n",
        "\n",
        "    if self.identity_downsamples is not None:\n",
        "      identity=self.identity_downsamples(identity)\n",
        "\n",
        "    x+=identity\n",
        "    x=self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "nuB-dWrp5YN2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, image_channels, num_classes):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels=64\n",
        "    self.conv1=nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "    self.bn1=nn.BatchNorm2d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    #ResNet layers starting from here\n",
        "    self.layer1=self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "    self.layer2=self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "    self.layer3=self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "    self.layer4=self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc=nn.Linear(512*4, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.maxpool(x)\n",
        "\n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        "\n",
        "    x=self.avgpool(x)\n",
        "    x=x.reshape(x.shape[0], -1)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
        "    identity_downsample=None\n",
        "    layers=[]\n",
        "\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\n",
        "      identity_downsample=nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride), nn.BatchNorm2d(out_channels*4))\n",
        "\n",
        "      layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
        "      self.in_channels=out_channels*4\n",
        "\n",
        "      for i in range(num_residual_blocks-1):\n",
        "        layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jo_0kJP3895b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,6,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet101(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,8,36,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet152(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,23,3], img_channels, num_classes)\n"
      ],
      "metadata": {
        "id": "vvjPZ06sEB6J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet50()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "auTkGaFtElpV",
        "outputId": "c217e8ad-02eb-4546-9f1f-8453407a550f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1600232209.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1600232209.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet101()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "WGvgzSTtImBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet152()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "Gm43AXHzImGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet50()\n",
        "print(\"ResNet-50 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet101()\n",
        "print(\"ResNet-101 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet152()\n",
        "print(\"ResNet-152 params:\", sum(p.numel() for p in net.parameters()))\n"
      ],
      "metadata": {
        "id": "jMhou0zkCNxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "5N3asFvrC-FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Lkjo1aDZC5w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ResNet50(img_channels=3, num_classes=10).to(device)\n"
      ],
      "metadata": {
        "id": "9XgNhw8fC_dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "_pESAf7BDBtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(net, trainloader, optimizer, criterion, device, epoch):\n",
        "    net.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(trainloader, leave=True)\n",
        "    for inputs, targets in loop:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        loop.set_description(f\"Epoch [{epoch}]\")\n",
        "        loop.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n",
        "\n",
        "    return running_loss/len(trainloader), 100.*correct/total\n"
      ],
      "metadata": {
        "id": "-wQI-QCyDDaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = \"./checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_loss, train_acc = train(net, trainloader, optimizer, criterion, device, epoch)\n",
        "    test_loss, test_acc = test(net, testloader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs} \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state': net.state_dict(),\n",
        "        'optimizer_state': optimizer.state_dict(),\n",
        "        'scheduler_state': scheduler.state_dict()\n",
        "    }\n",
        "    torch.save(state, f\"{checkpoint_dir}/resnet_checkpoint.pth\")\n"
      ],
      "metadata": {
        "id": "WQy8olURDFP-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}