{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCkGP0obsqInTjdGqvhKpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhbishtabhishek/Papers-Implemented/blob/main/ResNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "quq4sjg25PeL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, identity_downsamples=None, stride=1):\n",
        "    super(block, self).__init__()\n",
        "    self.expansion=4\n",
        "    self.conv1=nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1=nn.BatchNorm2d(out_channels)\n",
        "    self.conv2=nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2=nn.BatchNorm2d(out_channels)\n",
        "    self.conv3=nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3=nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.identity_downsamples=identity_downsamples\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity=x\n",
        "\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.bn2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv3(x)\n",
        "    x=self.bn3(x)\n",
        "\n",
        "    if self.identity_downsamples is not None:\n",
        "      identity=self.identity_downsamples(identity)\n",
        "\n",
        "    x+=identity\n",
        "    x=self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "nuB-dWrp5YN2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, image_channels, num_classes):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels=64\n",
        "    self.conv1=nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "    self.bn1=nn.BatchNorm2d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    #ResNet layers starting from here\n",
        "    self.layer1=self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "    self.layer2=self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "    self.layer3=self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "    self.layer4=self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc=nn.Linear(512*4, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.maxpool(x)\n",
        "\n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        "\n",
        "    x=self.avgpool(x)\n",
        "    x=x.reshape(x.shape[0], -1)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
        "    identity_downsample=None\n",
        "    layers=[]\n",
        "\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\n",
        "      identity_downsample=nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride), nn.BatchNorm2d(out_channels*4))\n",
        "\n",
        "      layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
        "      self.in_channels=out_channels*4\n",
        "\n",
        "      for i in range(num_residual_blocks-1):\n",
        "        layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jo_0kJP3895b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,6,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet101(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,8,36,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet152(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,23,3], img_channels, num_classes)\n"
      ],
      "metadata": {
        "id": "vvjPZ06sEB6J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet50()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auTkGaFtElpV",
        "outputId": "e6d9ef78-46df-4565-8978-c253fd95676f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet101()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGvgzSTtImBb",
        "outputId": "d6c89f37-7840-41b4-e053-9bc088487103"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet152()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm43AXHzImGC",
        "outputId": "b16a0cb1-f7a8-4419-ce1c-167e1c215b68"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet50()\n",
        "print(\"ResNet-50 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet101()\n",
        "print(\"ResNet-101 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet152()\n",
        "print(\"ResNet-152 params:\", sum(p.numel() for p in net.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMhou0zkCNxj",
        "outputId": "fd6efbec-a5f4-4327-c80e-fdf53f8021d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 params: 25583592\n",
            "ResNet-101 params: 60268520\n",
            "ResNet-152 params: 44601832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "5N3asFvrC-FT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkjo1aDZC5w6",
        "outputId": "e9c1b195-f605-4c99-a7ae-967ac4bc7fdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:14<00:00, 11.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ResNet50(img_channels=3, num_classes=10).to(device)\n"
      ],
      "metadata": {
        "id": "9XgNhw8fC_dW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "_pESAf7BDBtU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(net, trainloader, optimizer, criterion, device, epoch):\n",
        "    net.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(trainloader, leave=True)\n",
        "    for inputs, targets in loop:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        loop.set_description(f\"Epoch [{epoch}]\")\n",
        "        loop.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n",
        "\n",
        "    return running_loss/len(trainloader), 100.*correct/total\n",
        "\n"
      ],
      "metadata": {
        "id": "-wQI-QCyDDaC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, testloader, criterion, device):\n",
        "    net.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(testloader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "KhQTSWGA5fM8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZnEV7WR1dR5",
        "outputId": "7c85454d-c3ec-48bd-cac1-b894a86c1450"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/checkpoints/resnet_checkpoint.pth\"\n",
        "\n",
        "start_epoch = 0\n",
        "if os.path.isfile(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    net.load_state_dict(checkpoint['model_state'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(start_epoch + 1, num_epochs + 1):\n",
        "    train_loss, train_acc = train(net, trainloader, optimizer, criterion, device, epoch)\n",
        "    test_loss, test_acc = test(net, testloader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs} \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state': net.state_dict(),\n",
        "        'optimizer_state': optimizer.state_dict(),\n",
        "        'scheduler_state': scheduler.state_dict()\n",
        "    }\n",
        "    torch.save(state, checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQy8olURDFP-",
        "outputId": "f8bb8c63-c0d4-46ca-b313-f45cb215c096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [27]: 100%|██████████| 391/391 [10:20<00:00,  1.59s/it, acc=92.4, loss=0.00168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100 Train Loss: 0.2148 | Train Acc: 92.44% Test Loss: 0.4483 | Test Acc: 85.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [28]: 100%|██████████| 391/391 [10:18<00:00,  1.58s/it, acc=92.7, loss=0.00163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100 Train Loss: 0.2082 | Train Acc: 92.71% Test Loss: 0.4905 | Test Acc: 84.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [29]: 100%|██████████| 391/391 [10:19<00:00,  1.59s/it, acc=92.9, loss=0.0016]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100 Train Loss: 0.2045 | Train Acc: 92.85% Test Loss: 0.4571 | Test Acc: 85.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [30]: 100%|██████████| 391/391 [10:19<00:00,  1.58s/it, acc=96.9, loss=0.000757]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100 Train Loss: 0.0969 | Train Acc: 96.87% Test Loss: 0.3378 | Test Acc: 89.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [31]: 100%|██████████| 391/391 [10:20<00:00,  1.59s/it, acc=98, loss=0.000508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100 Train Loss: 0.0649 | Train Acc: 98.00% Test Loss: 0.3508 | Test Acc: 89.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [32]: 100%|██████████| 391/391 [10:17<00:00,  1.58s/it, acc=98.4, loss=0.000405]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100 Train Loss: 0.0518 | Train Acc: 98.45% Test Loss: 0.3571 | Test Acc: 89.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [33]: 100%|██████████| 391/391 [10:18<00:00,  1.58s/it, acc=98.8, loss=0.000325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100 Train Loss: 0.0416 | Train Acc: 98.82% Test Loss: 0.3713 | Test Acc: 89.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [34]: 100%|██████████| 391/391 [10:20<00:00,  1.59s/it, acc=98.8, loss=0.00029]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100 Train Loss: 0.0371 | Train Acc: 98.83% Test Loss: 0.3780 | Test Acc: 89.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [35]: 100%|██████████| 391/391 [10:20<00:00,  1.59s/it, acc=99, loss=0.000259]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100 Train Loss: 0.0331 | Train Acc: 99.02% Test Loss: 0.3973 | Test Acc: 89.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [36]: 100%|██████████| 391/391 [10:17<00:00,  1.58s/it, acc=99.2, loss=0.000219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100 Train Loss: 0.0280 | Train Acc: 99.20% Test Loss: 0.3995 | Test Acc: 89.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [37]:  10%|█         | 41/391 [01:05<09:22,  1.61s/it, acc=99.4, loss=0.000177]"
          ]
        }
      ]
    }
  ]
}