{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6cZEjZnkK4jQe1HnVJX74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhbishtabhishek/ResNet-Implementation-/blob/main/ResNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "quq4sjg25PeL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, identity_downsamples=None, stride=1):\n",
        "    super(block, self).__init__()\n",
        "    self.expansion=4\n",
        "    self.conv1=nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1=nn.BatchNorm2d(out_channels)\n",
        "    self.conv2=nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2=nn.BatchNorm2d(out_channels)\n",
        "    self.conv3=nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3=nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.identity_downsamples=identity_downsamples\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity=x\n",
        "\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    x=self.bn2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv3(x)\n",
        "    x=self.bn3(x)\n",
        "\n",
        "    if self.identity_downsamples is not None:\n",
        "      identity=self.identity_downsamples(identity)\n",
        "\n",
        "    x+=identity\n",
        "    x=self.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "nuB-dWrp5YN2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, image_channels, num_classes):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels=64\n",
        "    self.conv1=nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "    self.bn1=nn.BatchNorm2d(64)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    #ResNet layers starting from here\n",
        "    self.layer1=self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
        "    self.layer2=self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
        "    self.layer3=self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
        "    self.layer4=self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
        "\n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc=nn.Linear(512*4, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.maxpool(x)\n",
        "\n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        "\n",
        "    x=self.avgpool(x)\n",
        "    x=x.reshape(x.shape[0], -1)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
        "    identity_downsample=None\n",
        "    layers=[]\n",
        "\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\n",
        "      identity_downsample=nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride), nn.BatchNorm2d(out_channels*4))\n",
        "\n",
        "      layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
        "      self.in_channels=out_channels*4\n",
        "\n",
        "      for i in range(num_residual_blocks-1):\n",
        "        layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jo_0kJP3895b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,6,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet101(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,8,36,3], img_channels, num_classes)\n",
        "\n",
        "def ResNet152(img_channels=3, num_classes=1000):\n",
        "  return ResNet(block, [3,4,23,3], img_channels, num_classes)\n"
      ],
      "metadata": {
        "id": "vvjPZ06sEB6J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet50()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auTkGaFtElpV",
        "outputId": "51413915-719d-4153-a1a1-ad8d74e0209c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet101()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGvgzSTtImBb",
        "outputId": "95a1cbe8-e114-404f-85f2-eced859a419b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  net=ResNet152()\n",
        "  x=torch.randn(2,3,224,224)\n",
        "  y=net(x).to('cuda')\n",
        "  print(y.shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm43AXHzImGC",
        "outputId": "c977f2d3-ae1f-4dc8-ce37-e7634500aea0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet50()\n",
        "print(\"ResNet-50 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet101()\n",
        "print(\"ResNet-101 params:\", sum(p.numel() for p in net.parameters()))\n",
        "\n",
        "net = ResNet152()\n",
        "print(\"ResNet-152 params:\", sum(p.numel() for p in net.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMhou0zkCNxj",
        "outputId": "ba2ef322-59d9-4118-f3b1-212b7921755e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 params: 25583592\n",
            "ResNet-101 params: 60268520\n",
            "ResNet-152 params: 44601832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "metadata": {
        "id": "5N3asFvrC-FT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkjo1aDZC5w6",
        "outputId": "a3b31d10-e799-4188-c9a0-df8e8d29eff6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ResNet50(img_channels=3, num_classes=10).to(device)\n"
      ],
      "metadata": {
        "id": "9XgNhw8fC_dW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "_pESAf7BDBtU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(net, trainloader, optimizer, criterion, device, epoch):\n",
        "    net.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(trainloader, leave=True)\n",
        "    for inputs, targets in loop:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        loop.set_description(f\"Epoch [{epoch}]\")\n",
        "        loop.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n",
        "\n",
        "    return running_loss/len(trainloader), 100.*correct/total\n",
        "\n"
      ],
      "metadata": {
        "id": "-wQI-QCyDDaC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, testloader, criterion, device):\n",
        "    net.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in testloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(testloader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "KhQTSWGA5fM8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZnEV7WR1dR5",
        "outputId": "d2c869e6-1070-4501-af7e-24ac148b16d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDriveresnet_checkpoint.pth\"\n",
        "\n",
        "start_epoch = 0\n",
        "if os.path.isfile(checkpoint_path):\n",
        "    print(\"Loading checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    net.load_state_dict(checkpoint['model_state'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"Resumed from epoch {start_epoch}\")\n"
      ],
      "metadata": {
        "id": "U0GlJWAHq6uq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_loss, train_acc = train(net, trainloader, optimizer, criterion, device, epoch)\n",
        "    test_loss, test_acc = test(net, testloader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs} \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state': net.state_dict(),\n",
        "        'optimizer_state': optimizer.state_dict(),\n",
        "        'scheduler_state': scheduler.state_dict()\n",
        "    }\n",
        "    torch.save(state, f\"{checkpoint_dir}/resnet_checkpoint.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQy8olURDFP-",
        "outputId": "dcd158d6-7e87-42a1-99e0-ff4a92983cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1]: 100%|██████████| 391/391 [10:52<00:00,  1.67s/it, acc=48.3, loss=0.011]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 Train Loss: 1.4059 | Train Acc: 48.27% Test Loss: 1.3374 | Test Acc: 50.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2]: 100%|██████████| 391/391 [10:54<00:00,  1.67s/it, acc=54.1, loss=0.00981]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 Train Loss: 1.2545 | Train Acc: 54.09% Test Loss: 1.2206 | Test Acc: 57.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3]: 100%|██████████| 391/391 [10:55<00:00,  1.68s/it, acc=59.2, loss=0.00882]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 Train Loss: 1.1281 | Train Acc: 59.22% Test Loss: 1.1186 | Test Acc: 59.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4]: 100%|██████████| 391/391 [10:55<00:00,  1.68s/it, acc=62.5, loss=0.0081]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 Train Loss: 1.0364 | Train Acc: 62.47% Test Loss: 1.1100 | Test Acc: 60.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5]: 100%|██████████| 391/391 [10:54<00:00,  1.67s/it, acc=65.7, loss=0.00748]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 Train Loss: 0.9567 | Train Acc: 65.74% Test Loss: 0.9132 | Test Acc: 67.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6]: 100%|██████████| 391/391 [10:54<00:00,  1.67s/it, acc=69.1, loss=0.00678]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 Train Loss: 0.8675 | Train Acc: 69.14% Test Loss: 0.9230 | Test Acc: 67.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7]: 100%|██████████| 391/391 [10:54<00:00,  1.67s/it, acc=72, loss=0.00621]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 Train Loss: 0.7944 | Train Acc: 72.02% Test Loss: 0.8530 | Test Acc: 70.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8]: 100%|██████████| 391/391 [10:54<00:00,  1.67s/it, acc=74.5, loss=0.00567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 Train Loss: 0.7256 | Train Acc: 74.48% Test Loss: 0.7406 | Test Acc: 74.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9]: 100%|██████████| 391/391 [10:53<00:00,  1.67s/it, acc=77.1, loss=0.00508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 Train Loss: 0.6496 | Train Acc: 77.07% Test Loss: 0.7405 | Test Acc: 75.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10]: 100%|██████████| 391/391 [10:57<00:00,  1.68s/it, acc=79.3, loss=0.00467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 Train Loss: 0.5970 | Train Acc: 79.30% Test Loss: 0.6482 | Test Acc: 78.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11]: 100%|██████████| 391/391 [10:57<00:00,  1.68s/it, acc=80.9, loss=0.00427]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 Train Loss: 0.5457 | Train Acc: 80.93% Test Loss: 0.6991 | Test Acc: 78.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [12]: 100%|██████████| 391/391 [10:57<00:00,  1.68s/it, acc=82.5, loss=0.00395]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 Train Loss: 0.5053 | Train Acc: 82.50% Test Loss: 0.5734 | Test Acc: 80.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [13]: 100%|██████████| 391/391 [10:59<00:00,  1.69s/it, acc=83.6, loss=0.00368]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 Train Loss: 0.4711 | Train Acc: 83.55% Test Loss: 0.5681 | Test Acc: 80.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [14]: 100%|██████████| 391/391 [10:58<00:00,  1.68s/it, acc=84.8, loss=0.00344]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 Train Loss: 0.4396 | Train Acc: 84.80% Test Loss: 0.5876 | Test Acc: 79.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [15]: 100%|██████████| 391/391 [10:57<00:00,  1.68s/it, acc=86, loss=0.0032]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 Train Loss: 0.4088 | Train Acc: 85.98% Test Loss: 0.6335 | Test Acc: 82.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [16]: 100%|██████████| 391/391 [10:58<00:00,  1.69s/it, acc=86.3, loss=0.00304]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 Train Loss: 0.3884 | Train Acc: 86.32% Test Loss: 0.4964 | Test Acc: 83.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17]:  26%|██▌       | 100/391 [02:48<08:20,  1.72s/it, acc=87.9, loss=0.00271]"
          ]
        }
      ]
    }
  ]
}